# Use 2.1 for orbs
version: 2.1

# -------------------------------------------------------------------------------------
# Environments to run the jobs in
# -------------------------------------------------------------------------------------
gpu: &gpu
  environment:
    CUDA_VERSION: "11.1"
  machine:
    image: ubuntu-2004-cuda-11.4:202110-01
    resource_class: gpu.nvidia.medium.multi


# -------------------------------------------------------------------------------------
# Re-usable commands
# -------------------------------------------------------------------------------------
cache_key: &cache_key cache-key-{{ checksum ".circleci/config.yml" }}-{{ checksum "setup.py"}}

install_dep_common: &install_dep_common
  - run:
      name: Install Common Dependencies
      command: |
        source $BASH_ENV
        source activate metaseq
        # Fixed version to work around https://github.com/pytorch/pytorch/pull/69904
        $CONDA_PYTHON -m pip install setuptools==59.5.0
        pip install -i https://test.pypi.org/simple/ bitsandbytes-cuda113 -U
        python -c 'import torch; print("Torch version:", torch.__version__)'
        python -m torch.utils.collect_env
        # Need to install ninja build system
        sudo apt-get update
        sudo apt-get install ninja-build
install_dep_fused_ops: &install_dep_fused_ops
  - run:
      name: Install Megatron/Apex Dependencies
      working_directory: ~/
      no_output_timeout: 5h
      # because of https://github.com/NVIDIA/apex/issues/1252 we need to pin to a specific apex commit
      command: |
        source $BASH_ENV
        source activate metaseq
        pip install --upgrade setuptools
        if ! python -c 'import apex'; then
          git clone https://github.com/NVIDIA/apex
          cd apex
          git checkout 265b451de8ba9bfcb67edc7360f3d8772d0a8bea
          sed -i '32 i \ \ \ \ return' setup.py
          pip install -v --no-cache-dir --global-option="--cpp_ext" --global-option="--cuda_ext" --global-option="--deprecated_fused_adam" --global-option="--xentropy" --global-option="--fast_multihead_attn" ./ &
          cd ~/
        fi
        if ! python -c 'import megatron_lm'; then
          git clone --depth=1 --branch fairseq_v3 https://github.com/ngoyal2707/Megatron-LM.git
          cd Megatron-LM
          pip install -r requirements.txt
          pip install -e .
          cd ~/
        fi
# Remove this when we get a new fairscale release
install_fairscale: &install_fairscale
  - run:
      name: Install Fairscale and xFormers from Source
      working_directory: ~/
      command: |
        source $BASH_ENV
        source activate metaseq
        if ! python -c 'import fairscale'; then
            git clone https://github.com/facebookresearch/fairscale.git
            cd fairscale
            git checkout 1bc96fa8c69def6d990e42bfbd75f86146ce29bd
            pip install .
            cd ~/
        fi
        if ! python -c 'import xformers'; then
            git clone https://github.com/facebookresearch/xformers.git
            cd xformers
            git submodule update --init --recursive
            pip install .
            cd ~/
        fi
install_dep_pt112: &install_dep_pt112
  - run:
      name: Install Pytorch Dependencies
      command: |
        source $BASH_ENV
        source activate metaseq
        python -m pip install --upgrade setuptools
        # conda install torchvision cudatoolkit=11.3 -c pytorch -q
        python -m pip install torch==1.12.1+cu113 torchaudio==0.12.1 torchvision==0.13.1+cu113 -f https://download.pytorch.org/whl/torch_stable.html
        conda install -c nvidia cuda-nvcc -c nvidia -q -y
        echo "path = $PATH"
        echo "nvcc version = $(nvcc --version)"
        python -c 'import torch; print("Torch version:", torch.__version__)'
install_pytorch_dep: &install_pytorch_dep
  - parameters:
        version_str:
          type: string
          default: "/dev/non_exist"  # Default to error out
  - run:
      name: Install Pytorch Dependencies
      command: |
        source $BASH_ENV
        source activate metaseq
        $CONDA_PYTHON -m pip install --upgrade setuptools
        echo "<<parameters.version_str>>"
        pip install  <<parameters.version_str>> -f https://download.pytorch.org/whl/torch_stable.html
        python -c 'import torch; print("Torch version:", torch.__version__)'
install_repo: &install_repo
  - run:
      name: Install Repository
      command: |
        source $BASH_ENV
        source activate metaseq
        pip install -e .[dev,few_shot,gpu]
        python setup.py build_ext --inplace
check_nvidia_driver: &check_nvidia_driver
  - run:
      name: Check NVIDIA Driver
      working_directory: ~/
      command: |
        pyenv versions
        nvidia-smi
create_conda_env: &create_conda_env
  run:
      name: Install and Create Conda Environment
      command: |
        curl -o ~/miniconda.sh -O  https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh
        chmod +x ~/miniconda.sh
        ~/miniconda.sh -b -p $HOME/miniconda
        rm ~/miniconda.sh
        echo 'export PATH=$HOME/miniconda/bin:$PATH' >> $BASH_ENV
        echo $(which python)
        echo 'export CONDA_PYTHON=/home/circleci/miniconda/bin/python'  >>  $BASH_ENV
        source $BASH_ENV
        if [ ! -d ~/miniconda/envs/metaseq ]
        then
          conda create -y -n metaseq python=3.9 pip
        fi
        source activate metaseq
        python --version
        pip install --upgrade pip
download_and_configure_125m_with_hf_dependencies: &download_and_configure_125m_with_hf_dependencies
  - run:
      name: Download and configure a 125m checkpoint with HF dependencies
      working_directory: ~/metaseq/gpu_tests
      command: |
        source $BASH_ENV
        source activate metaseq
        wget https://dl.fbaipublicfiles.com/opt/test_artifacts/125m_with_hf_dependencies.tar.gz
        tar -xvzf ./125m_with_hf_dependencies.tar.gz -C .
        python -m metaseq.scripts.convert_to_singleton ./125m
        python -m transformers.models.opt.convert_opt_original_pytorch_checkpoint_to_pytorch --pytorch_dump_folder_path ./125m/ --hf_config ./125m/config.json --fairseq_path ./125m/restored.pt 
commands:

  gpu_pre: &gpu_pre
    steps:
      - run:
          name: Setup Ramdisk
          command: sudo mount -t tmpfs tmpfs ~/
      - checkout
      - <<: *check_nvidia_driver
      - <<: *create_conda_env
      - restore_cache:
          key: *cache_key

  gpu_post: &gpu_post
    steps:
      - <<: *install_dep_common
      - <<: *install_fairscale
      - <<: *install_dep_fused_ops
      - <<: *install_repo
      - <<: *download_and_configure_125m_with_hf_dependencies
      - save_cache:
          paths:
            - ~/miniconda/envs/metaseq/lib/python3.9/site-packages
          key: *cache_key
      - run:
          name: Run Unit Tests
          command: |
            source $BASH_ENV
            source activate metaseq
            python -m pytest --junitxml=test-results/junit.xml gpu_tests
      - store_test_results:
          path: test-results


# -------------------------------------------------------------------------------------
# Jobs to run
# -------------------------------------------------------------------------------------

jobs:

  gpu_tests_pt112:
    <<: *gpu

    working_directory: ~/metaseq

    steps:
      - gpu_pre
      - <<: *install_dep_pt112
      - gpu_post


workflows:
  version: 2
  build:
    jobs:
      - gpu_tests_pt112
